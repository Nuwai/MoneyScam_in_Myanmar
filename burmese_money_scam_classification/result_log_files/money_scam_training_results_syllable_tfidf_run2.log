2025-03-09 20:17:55 - Training Started...
2025-03-09 20:17:55 - Training Model: Logistic Regression
2025-03-09 20:17:59 - Training Model: Decision Tree
2025-03-09 20:18:08 - Training Model: Random Forest
Original Class Distribution: {0: 2481, 1: 10905, 2: 5961}
Full Training Set Size: 15477
Test Set Size: 3870
Training Pool Size: 12381
Validation Set Size: 3096
Selected Vectorizer Type is tfidf.

========================================
Training Model: Logistic Regression
========================================

----------------------------------------
Evaluating Fold 1 (Logistic Regression)
----------------------------------------
Accuracy: 0.8583
Confusion Matrix:
 [[ 250   42   26]
 [ 134 1232   30]
 [  82   37  644]]
Classification Report:
               precision    recall  f1-score   support

           0       0.54      0.79      0.64       318
           1       0.94      0.88      0.91      1396
           2       0.92      0.84      0.88       763

    accuracy                           0.86      2477
   macro avg       0.80      0.84      0.81      2477
weighted avg       0.88      0.86      0.87      2477

F1-Score: 0.8661
ROC-AUC: 0.9566
Log Loss: 0.3857
----------------------------------------


----------------------------------------
Evaluating Fold 2 (Logistic Regression)
----------------------------------------
Accuracy: 0.8566
Confusion Matrix:
 [[ 257   28   32]
 [ 131 1211   54]
 [  68   42  653]]
Classification Report:
               precision    recall  f1-score   support

           0       0.56      0.81      0.66       317
           1       0.95      0.87      0.90      1396
           2       0.88      0.86      0.87       763

    accuracy                           0.86      2476
   macro avg       0.80      0.84      0.81      2476
weighted avg       0.88      0.86      0.86      2476

F1-Score: 0.8632
ROC-AUC: 0.9607
Log Loss: 0.3856
----------------------------------------


----------------------------------------
Evaluating Fold 3 (Logistic Regression)
----------------------------------------
Accuracy: 0.8615
Confusion Matrix:
 [[ 255   32   30]
 [ 132 1216   48]
 [  70   31  662]]
Classification Report:
               precision    recall  f1-score   support

           0       0.56      0.80      0.66       317
           1       0.95      0.87      0.91      1396
           2       0.89      0.87      0.88       763

    accuracy                           0.86      2476
   macro avg       0.80      0.85      0.82      2476
weighted avg       0.88      0.86      0.87      2476

F1-Score: 0.8684
ROC-AUC: 0.9626
Log Loss: 0.3697
----------------------------------------


----------------------------------------
Evaluating Fold 4 (Logistic Regression)
----------------------------------------
Accuracy: 0.8631
Confusion Matrix:
 [[ 251   35   32]
 [ 119 1227   49]
 [  71   33  659]]
Classification Report:
               precision    recall  f1-score   support

           0       0.57      0.79      0.66       318
           1       0.95      0.88      0.91      1395
           2       0.89      0.86      0.88       763

    accuracy                           0.86      2476
   macro avg       0.80      0.84      0.82      2476
weighted avg       0.88      0.86      0.87      2476

F1-Score: 0.8692
ROC-AUC: 0.9601
Log Loss: 0.3786
----------------------------------------


----------------------------------------
Evaluating Fold 5 (Logistic Regression)
----------------------------------------
Accuracy: 0.8631
Confusion Matrix:
 [[ 254   29   35]
 [ 122 1223   51]
 [  73   29  660]]
Classification Report:
               precision    recall  f1-score   support

           0       0.57      0.80      0.66       318
           1       0.95      0.88      0.91      1396
           2       0.88      0.87      0.88       762

    accuracy                           0.86      2476
   macro avg       0.80      0.85      0.82      2476
weighted avg       0.88      0.86      0.87      2476

F1-Score: 0.8696
ROC-AUC: 0.9612
Log Loss: 0.3830
----------------------------------------


Average F1-Score for Logistic Regression: 0.8673

========================================
Training Model: Decision Tree
========================================

----------------------------------------
Evaluating Fold 1 (Decision Tree)
----------------------------------------
Accuracy: 0.8155
Confusion Matrix:
 [[ 199   77   42]
 [  92 1219   85]
 [  79   82  602]]
Classification Report:
               precision    recall  f1-score   support

           0       0.54      0.63      0.58       318
           1       0.88      0.87      0.88      1396
           2       0.83      0.79      0.81       763

    accuracy                           0.82      2477
   macro avg       0.75      0.76      0.75      2477
weighted avg       0.82      0.82      0.82      2477

F1-Score: 0.8182
ROC-AUC: 0.8405
Log Loss: 6.1549
----------------------------------------


----------------------------------------
Evaluating Fold 2 (Decision Tree)
----------------------------------------
Accuracy: 0.8090
Confusion Matrix:
 [[ 187   73   57]
 [  96 1206   94]
 [  74   79  610]]
Classification Report:
               precision    recall  f1-score   support

           0       0.52      0.59      0.55       317
           1       0.89      0.86      0.88      1396
           2       0.80      0.80      0.80       763

    accuracy                           0.81      2476
   macro avg       0.74      0.75      0.74      2476
weighted avg       0.81      0.81      0.81      2476

F1-Score: 0.8115
ROC-AUC: 0.8321
Log Loss: 6.3766
----------------------------------------


----------------------------------------
Evaluating Fold 3 (Decision Tree)
----------------------------------------
Accuracy: 0.8227
Confusion Matrix:
 [[ 187   84   46]
 [  88 1214   94]
 [  52   75  636]]
Classification Report:
               precision    recall  f1-score   support

           0       0.57      0.59      0.58       317
           1       0.88      0.87      0.88      1396
           2       0.82      0.83      0.83       763

    accuracy                           0.82      2476
   macro avg       0.76      0.76      0.76      2476
weighted avg       0.82      0.82      0.82      2476

F1-Score: 0.8234
ROC-AUC: 0.8381
Log Loss: 6.0534
----------------------------------------


----------------------------------------
Evaluating Fold 4 (Decision Tree)
----------------------------------------
Accuracy: 0.8199
Confusion Matrix:
 [[ 187   75   56]
 [  92 1215   88]
 [  66   69  628]]
Classification Report:
               precision    recall  f1-score   support

           0       0.54      0.59      0.56       318
           1       0.89      0.87      0.88      1395
           2       0.81      0.82      0.82       763

    accuracy                           0.82      2476
   macro avg       0.75      0.76      0.75      2476
weighted avg       0.82      0.82      0.82      2476

F1-Score: 0.8217
ROC-AUC: 0.8372
Log Loss: 6.1380
----------------------------------------


----------------------------------------
Evaluating Fold 5 (Decision Tree)
----------------------------------------
Accuracy: 0.8279
Confusion Matrix:
 [[ 204   72   42]
 [  99 1207   90]
 [  59   64  639]]
Classification Report:
               precision    recall  f1-score   support

           0       0.56      0.64      0.60       318
           1       0.90      0.86      0.88      1396
           2       0.83      0.84      0.83       762

    accuracy                           0.83      2476
   macro avg       0.76      0.78      0.77      2476
weighted avg       0.83      0.83      0.83      2476

F1-Score: 0.8305
ROC-AUC: 0.8516
Log Loss: 5.7498
----------------------------------------


Average F1-Score for Decision Tree: 0.8211

========================================
Training Model: Random Forest
========================================

----------------------------------------
Evaluating Fold 1 (Random Forest)
----------------------------------------
Accuracy: 0.8720
Confusion Matrix:
 [[ 183   95   40]
 [  33 1330   33]
 [  38   78  647]]2025-03-09 20:18:53 - Training Model: XGBoost
2025-03-09 20:20:04 - Training Model: SVM

Classification Report:
               precision    recall  f1-score   support

           0       0.72      0.58      0.64       318
           1       0.88      0.95      0.92      1396
           2       0.90      0.85      0.87       763

    accuracy                           0.87      2477
   macro avg       0.83      0.79      0.81      2477
weighted avg       0.87      0.87      0.87      2477

F1-Score: 0.8680
ROC-AUC: 0.9625
Log Loss: 0.3458
----------------------------------------


----------------------------------------
Evaluating Fold 2 (Random Forest)
----------------------------------------
Accuracy: 0.8813
Confusion Matrix:
 [[ 190   87   40]
 [  40 1329   27]
 [  31   69  663]]
Classification Report:
               precision    recall  f1-score   support

           0       0.73      0.60      0.66       317
           1       0.89      0.95      0.92      1396
           2       0.91      0.87      0.89       763

    accuracy                           0.88      2476
   macro avg       0.84      0.81      0.82      2476
weighted avg       0.88      0.88      0.88      2476

F1-Score: 0.8780
ROC-AUC: 0.9626
Log Loss: 0.3906
----------------------------------------


----------------------------------------
Evaluating Fold 3 (Random Forest)
----------------------------------------
Accuracy: 0.8910
Confusion Matrix:
 [[ 190   96   31]
 [  25 1349   22]
 [  32   64  667]]
Classification Report:
               precision    recall  f1-score   support

           0       0.77      0.60      0.67       317
           1       0.89      0.97      0.93      1396
           2       0.93      0.87      0.90       763

    accuracy                           0.89      2476
   macro avg       0.86      0.81      0.83      2476
weighted avg       0.89      0.89      0.89      2476

F1-Score: 0.8871
ROC-AUC: 0.9682
Log Loss: 0.3541
----------------------------------------


----------------------------------------
Evaluating Fold 4 (Random Forest)
----------------------------------------
Accuracy: 0.8740
Confusion Matrix:
 [[ 178   99   41]
 [  33 1327   35]
 [  33   71  659]]
Classification Report:
               precision    recall  f1-score   support

           0       0.73      0.56      0.63       318
           1       0.89      0.95      0.92      1395
           2       0.90      0.86      0.88       763

    accuracy                           0.87      2476
   macro avg       0.84      0.79      0.81      2476
weighted avg       0.87      0.87      0.87      2476

F1-Score: 0.8695
ROC-AUC: 0.9584
Log Loss: 0.4222
----------------------------------------


----------------------------------------
Evaluating Fold 5 (Random Forest)
----------------------------------------
Accuracy: 0.8857
Confusion Matrix:
 [[ 187   81   50]
 [  39 1325   32]
 [  26   55  681]]
Classification Report:
               precision    recall  f1-score   support

           0       0.74      0.59      0.66       318
           1       0.91      0.95      0.93      1396
           2       0.89      0.89      0.89       762

    accuracy                           0.89      2476
   macro avg       0.85      0.81      0.83      2476
weighted avg       0.88      0.89      0.88      2476

F1-Score: 0.8821
ROC-AUC: 0.9646
Log Loss: 0.3516
----------------------------------------


Average F1-Score for Random Forest: 0.8770

========================================
Training Model: XGBoost
========================================

----------------------------------------
Evaluating Fold 1 (XGBoost)
----------------------------------------
Accuracy: 0.8825
Confusion Matrix:
 [[ 192   87   39]
 [  34 1337   25]
 [  36   70  657]]
Classification Report:
               precision    recall  f1-score   support

           0       0.73      0.60      0.66       318
           1       0.89      0.96      0.93      1396
           2       0.91      0.86      0.89       763

    accuracy                           0.88      2477
   macro avg       0.85      0.81      0.82      2477
weighted avg       0.88      0.88      0.88      2477

F1-Score: 0.8792
ROC-AUC: 0.9681
Log Loss: 0.2987
----------------------------------------


----------------------------------------
Evaluating Fold 2 (XGBoost)
----------------------------------------
Accuracy: 0.8837
Confusion Matrix:
 [[ 204   71   42]
 [  42 1319   35]
 [  26   72  665]]
Classification Report:
               precision    recall  f1-score   support

           0       0.75      0.64      0.69       317
           1       0.90      0.94      0.92      1396
           2       0.90      0.87      0.88       763

    accuracy                           0.88      2476
   macro avg       0.85      0.82      0.83      2476
weighted avg       0.88      0.88      0.88      2476

F1-Score: 0.8814
ROC-AUC: 0.9697
Log Loss: 0.2906
----------------------------------------


----------------------------------------
Evaluating Fold 3 (XGBoost)
----------------------------------------
Accuracy: 0.8938
Confusion Matrix:
 [[ 195   85   37]
 [  27 1337   32]
 [  29   53  681]]
Classification Report:
               precision    recall  f1-score   support

           0       0.78      0.62      0.69       317
           1       0.91      0.96      0.93      1396
           2       0.91      0.89      0.90       763

    accuracy                           0.89      2476
   macro avg       0.86      0.82      0.84      2476
weighted avg       0.89      0.89      0.89      2476

F1-Score: 0.8904
ROC-AUC: 0.9703
Log Loss: 0.2844
----------------------------------------


----------------------------------------
Evaluating Fold 4 (XGBoost)
----------------------------------------
Accuracy: 0.8845
Confusion Matrix:
 [[ 189   86   43]
 [  39 1322   34]
 [  25   59  679]]
Classification Report:
               precision    recall  f1-score   support

           0       0.75      0.59      0.66       318
           1       0.90      0.95      0.92      1395
           2       0.90      0.89      0.89       763

    accuracy                           0.88      2476
   macro avg       0.85      0.81      0.83      2476
weighted avg       0.88      0.88      0.88      2476

F1-Score: 0.8810
ROC-AUC: 0.9676
Log Loss: 0.2972
----------------------------------------


----------------------------------------
Evaluating Fold 5 (XGBoost)
----------------------------------------
Accuracy: 0.8865
Confusion Matrix:
 [[ 194   71   53]
 [  44 1320   32]
 [  25   56  681]]
Classification Report:
               precision    recall  f1-score   support

           0       0.74      0.61      0.67       318
           1       0.91      0.95      0.93      1396
           2       0.89      0.89      0.89       762

    accuracy                           0.89      2476
   macro avg       0.85      0.82      0.83      2476
weighted avg       0.88      0.89      0.88      2476

F1-Score: 0.8836
ROC-AUC: 0.9688
Log Loss: 0.2887
----------------------------------------


Average F1-Score for XGBoost: 0.8831

========================================
Training Model: SVM
========================================

----------------------------------------
Evaluating Fold 1 (SVM)
----------------------------------------
Accuracy: 0.8825
Confusion Matrix:
 [[ 237   55   26]
 [  86 1283   27]
 [  49   48  666]]
Classification Report:
               precision    recall  f1-score   support

           0       0.64      0.75      0.69       318
           1       0.93      0.92      0.92      1396
           2       0.93      0.87      0.90       763

    accuracy                           0.88      2477
   macro avg       0.83      0.85      0.84      2477
weighted avg       0.89      0.88      0.88      2477

F1-Score: 0.8849
ROC-AUC: 0.9610
Log Loss: 0.3200
----------------------------------------


----------------------------------------
Evaluating Fold 2 (SVM)
----------------------------------------
Accuracy: 0.87762025-03-09 20:24:21 - Training Model: Naive Bayes

Confusion Matrix:
 [[ 251   35   31]
 [  90 1256   50]
 [  50   47  666]]
Classification Report:
               precision    recall  f1-score   support

           0       0.64      0.79      0.71       317
           1       0.94      0.90      0.92      1396
           2       0.89      0.87      0.88       763

    accuracy                           0.88      2476
   macro avg       0.82      0.85      0.84      2476
weighted avg       0.89      0.88      0.88      2476

F1-Score: 0.8806
ROC-AUC: 0.9642
Log Loss: 0.3114
----------------------------------------


----------------------------------------
Evaluating Fold 3 (SVM)
----------------------------------------
Accuracy: 0.8922
Confusion Matrix:
 [[ 243   46   28]
 [  77 1282   37]
 [  41   38  684]]
Classification Report:
               precision    recall  f1-score   support

           0       0.67      0.77      0.72       317
           1       0.94      0.92      0.93      1396
           2       0.91      0.90      0.90       763

    accuracy                           0.89      2476
   macro avg       0.84      0.86      0.85      2476
weighted avg       0.90      0.89      0.89      2476

F1-Score: 0.8940
ROC-AUC: 0.9683
Log Loss: 0.2962
----------------------------------------


----------------------------------------
Evaluating Fold 4 (SVM)
----------------------------------------
Accuracy: 0.8893
Confusion Matrix:
 [[ 249   37   32]
 [  84 1271   40]
 [  51   30  682]]
Classification Report:
               precision    recall  f1-score   support

           0       0.65      0.78      0.71       318
           1       0.95      0.91      0.93      1395
           2       0.90      0.89      0.90       763

    accuracy                           0.89      2476
   macro avg       0.83      0.86      0.85      2476
weighted avg       0.90      0.89      0.89      2476

F1-Score: 0.8922
ROC-AUC: 0.9646
Log Loss: 0.3077
----------------------------------------


----------------------------------------
Evaluating Fold 5 (SVM)
----------------------------------------
Accuracy: 0.8849
Confusion Matrix:
 [[ 240   39   39]
 [  90 1268   38]
 [  39   40  683]]
Classification Report:
               precision    recall  f1-score   support

           0       0.65      0.75      0.70       318
           1       0.94      0.91      0.92      1396
           2       0.90      0.90      0.90       762

    accuracy                           0.88      2476
   macro avg       0.83      0.85      0.84      2476
weighted avg       0.89      0.88      0.89      2476

F1-Score: 0.8872
ROC-AUC: 0.9662
Log Loss: 0.3102
----------------------------------------


Average F1-Score for SVM: 0.8878

========================================
Training Model: Naive Bayes
========================================

----------------------------------------
Evaluating Fold 1 (Naive Bayes)
----------------------------------------
Accuracy: 0.8478
Confusion Matrix:
 [[ 158  108   52]
 [  48 1311   37]
 [  20  112  631]]
Classification Report:
               precision    recall  f1-score   support

           0       0.70      0.50      0.58       318
           1       0.86      0.94      0.90      1396
           2       0.88      0.83      0.85       763

    accuracy                           0.85      2477
   macro avg       0.81      0.75      0.78      2477
weighted avg       0.84      0.85      0.84      2477

F1-Score: 0.8416
ROC-AUC: 0.9519
Log Loss: 0.3819
----------------------------------------


----------------------------------------
Evaluating Fold 2 (Naive Bayes)
----------------------------------------
Accuracy: 0.8558
Confusion Matrix:
 [[ 157  114   46]
 [  39 1317   40]
 [   9  109  645]]
Classification Report:
               precision    recall  f1-score   support

           0       0.77      0.50      0.60       317
           1       0.86      0.94      0.90      1396
           2       0.88      0.85      0.86       763

    accuracy                           0.86      2476
   macro avg       0.83      0.76      0.79      2476
weighted avg       0.85      0.86      0.85      2476

F1-Score: 0.8489
ROC-AUC: 0.9579
Log Loss: 0.3648
----------------------------------------


----------------------------------------
Evaluating Fold 3 (Naive Bayes)
----------------------------------------
Accuracy: 0.8570
Confusion Matrix:
 [[ 155  101   61]
 [  42 1308   46]
 [   9   95  659]]
Classification Report:
               precision    recall  f1-score   support

           0       0.75      0.49      0.59       317
           1       0.87      0.94      0.90      1396
           2       0.86      0.86      0.86       763

    accuracy                           0.86      2476
   macro avg       0.83      0.76      0.79      2476
weighted avg       0.85      0.86      0.85      2476

F1-Score: 0.8501
ROC-AUC: 0.9569
Log Loss: 0.3653
----------------------------------------


----------------------------------------
Evaluating Fold 4 (Naive Bayes)
----------------------------------------
Accuracy: 0.8558
Confusion Matrix:
 [[ 149  117   52]
 [  37 1321   37]
 [  11  103  649]]
Classification Report:
               precision    recall  f1-score   support

           0       0.76      0.47      0.58       318
           1       0.86      0.95      0.90      1395
           2       0.88      0.85      0.86       763

    accuracy                           0.86      2476
   macro avg       0.83      0.76      0.78      2476
weighted avg       0.85      0.86      0.85      2476

F1-Score: 0.8478
ROC-AUC: 0.9565
Log Loss: 0.3691
----------------------------------------


----------------------------------------
Evaluating Fold 5 (Naive Bayes)
----------------------------------------
Accuracy: 0.8554
Confusion Matrix:
 [[ 164  103   51]
 [  48 1301   47]
 [   4  105  653]]
Classification Report:
               precision    recall  f1-score   support

           0       0.76      0.52      0.61       318
           1       0.86      0.93      0.90      1396
           2       0.87      0.86      0.86       762

    accuracy                           0.86      2476
   macro avg       0.83      0.77      0.79      2476
weighted avg       0.85      0.86      0.85      2476

F1-Score: 0.8495
ROC-AUC: 0.9561
Log Loss: 0.3733
----------------------------------------


Average F1-Score for Naive Bayes: 0.8476

======================================================================
Model Performance Summary
======================================================================
+---------------------+--------------------+
| Model               |   Average F1-Score |
+=====================+====================+
| Logistic Regression |             0.8673 |
+---------------------+--------------------+
| Decision Tree       |             0.8211 |
+---------------------+--------------------+
| Random Forest       |             0.877  |
+---------------------+--------------------+
| XGBoost             |             0.8831 |
+---------------------+--------------------+
| SVM                 |             0.8878 |
+---------------------+--------------------+
| Naive Bayes         |             0.8476 |
+---------------------+--------------------+

======================================================================
Best Model: SVM (F1-Score: 0.8878)
======================================================================

========================================
Hyperparameter Tuning for SVM
========================================
Best Hyperparameters for SVM: {'classifier__kernel': 'rbf', 'classifier__gamma': 1, 'classifier__degree': 3, 'classifier__C': 0.5}

========================================
Final Evaluation on Test Set
========================================
Accuracy: 0.8814
Confusion Matrix:
 [[ 410   49   37]
 [ 146 1971   64]
 [  93   70 1030]]
Classification Report:
               precision    recall  f1-score   support

           0       0.63      0.83      0.72       496
           1       0.94      0.90      0.92      2181
           2       0.91      0.86      0.89      1193

    accuracy                           0.88      3870
   macro avg       0.83      0.86      0.84      3870
weighted avg       0.89      0.88      0.89      3870

F1-Score: 0.8852
Precision: 0.8932
Recall: 0.8814
ROC-AUC: 0.9673
Log Loss: 0.3059
----------------------------------------


Training Complete. Logs saved in: C:\Users\nuwai\Documents\Sophia_Skill_Development\Sophia_projects\Burmese Scam Detector\burmese_money_scam_classification\money_scam_training_results.log
